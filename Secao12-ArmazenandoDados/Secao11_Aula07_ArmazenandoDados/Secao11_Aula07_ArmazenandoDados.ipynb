{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armazenando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armazenando o resultado do scraping no MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo da aula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta aula vamos criar uma aplicação para navegar em artigos do Wikipedia, buscando os links do artigo e armazenando as urls, títulos e conteúdo das páginas percorridas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abra o MySQL Workbench, conecte ao seu banco de dados e, na área schema crie um schema chamado scraping. Escolha o charset utf8 para que o banco suporte a maioria dos caracteres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagem1](imagens\\Imagem1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagem2](imagens\\Imagem2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagem3](imagens\\Imagem3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagem4](imagens\\Imagem4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagem5](imagens\\Imagem5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abra uma janela de consulta e execute o script para criação da tabela (código disponibilizado junto à aula)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagem6](imagens\\Imagem6.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE `scraping`.`paginas` (\n",
    "  `id` INT NOT NULL AUTO_INCREMENT,\n",
    "  `titulo` VARCHAR(200) NULL,\n",
    "  `url` VARCHAR(200) NULL,\n",
    "  `conteudo` VARCHAR(10000) CHARACTER SET 'utf8' NULL,\n",
    "  `data` TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP,\n",
    "  PRIMARY KEY (`id`))\n",
    "ENGINE = InnoDB\n",
    "DEFAULT CHARACTER SET = utf8;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando o algoritmo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos importar as bibliotecas necessárias."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import mysql.connector\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois vamos implementar a conexão com o banco."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dados_conexao = {\"user\":\"root\", \"password\":\"1234\", \"host\":\"127.0.0.1\", \"database\":\"scraping\", \"charset\":\"utf8\"}\n",
    "conexao = mysql.connector.connect(**dados_conexao)\n",
    "cursor = conexao.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementando o método para gravar os dados."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def gravar(titulo, url, conteudo):\n",
    "    cursor.execute('INSERT INTO paginas (titulo, url, conteudo)'\n",
    "                   'VALUES (%s, %s, %s)', (titulo, url, conteudo))\n",
    "    conexao.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementando o método para retornar os links da página."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getLinks(urlArtigo):\n",
    "    url = 'http://pt.wikipedia.org'+urlArtigo\n",
    "    html = urlopen(url)\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    titulo = bs.find('h1').get_text()\n",
    "    conteudo = bs.find('div', {'id':'mw-content-text'}).find('p').get_text()\n",
    "    gravar(titulo, url, conteudo)\n",
    "    return bs.find('div', {'id':'bodyContent'}).\\\n",
    "        findAll('a', href=re.compile('^(/wiki/)((?!:).)*$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizando o programa."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "links = getLinks('/wiki/Copa_do_Mundo_FIFA_de_2026')\n",
    "\n",
    "try:\n",
    "    contador = 1\n",
    "    while len(links) > 0 and contador <= 10:\n",
    "        novoArtigo = links[random.randint(0, len(links)-1)].attrs['href']\n",
    "        print(str(contador) + \" -> \" + novoArtigo)\n",
    "        links = getLinks(novoArtigo)\n",
    "        contador += 1\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conexao.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
